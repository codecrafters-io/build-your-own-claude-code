@@ -7,55 +7,51 @@

 def call_llm(client, prompt):
     chat_completion = client.chat.completions.create(
         model="anthropic/claude-haiku-4.5",
         messages=[
             {"role": "user", "content": prompt}
         ]
     )

     if len(chat_completion.choices) == 0:
         raise RuntimeError("no choices in response")

     content = chat_completion.choices[0].message.content
     if not content:
         raise RuntimeError("empty content in response")

     return content


 def fatal(message):
     print(f"error: {message}", file=sys.stderr)
     sys.exit(1)


 def main():
-    # You can use print statements as follows for debugging, they'll be visible when running tests.
-    print("Logs from your program will appear here!", file=sys.stderr)
-
     parser = argparse.ArgumentParser()
     parser.add_argument("-p", required=True, help="Prompt to send to LLM")
     args = parser.parse_args()

     api_key = os.getenv("OPENROUTER_API_KEY")
     if not api_key:
         fatal("OPENROUTER_API_KEY environment variable is not set")

     base_url = os.getenv("OPENROUTER_BASE_URL")
     if not base_url:
         fatal("OPENROUTER_BASE_URL environment variable is not set")

-    # TODO: Uncomment the code below to pass the first stage
-    # client = OpenAI(
-    #     api_key=api_key,
-    #     base_url=base_url,
-    # )
-    #
-    # try:
-    #     content = call_llm(client, args.p)
-    #     print(content)
-    # except Exception as e:
-    #     fatal(str(e))
+    client = OpenAI(
+        api_key=api_key,
+        base_url=base_url,
+    )
+
+    try:
+        content = call_llm(client, args.p)
+        print(content)
+    except Exception as e:
+        fatal(str(e))


 if __name__ == "__main__":
     main()
